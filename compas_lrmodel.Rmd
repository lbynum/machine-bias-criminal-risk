---
title: "COMPAS Data Modeling"
author: "Lucius Bynum, Preethi Seshadri"
date: "19 November 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, cache=TRUE)
options(digits=4)

library(DBI)
library(dplyr)
library(caret)
```

# Compas Scores Two Years

```{r}
compas_scores <- read.csv('compas-scores-two-years.csv')
summary(compas_scores)
```
```{r}
nrow(compas_scores)
length(unique(compas_scores$c_charge_desc))
```

Now we will perform the same cleaning/filtering they performed in order to maintain the same data.
```{r}
compas_scores <- compas_scores %>%
  filter(days_b_screening_arrest <= 30) %>%
  filter(days_b_screening_arrest >= -30) %>%
  filter(is_recid != -1) %>%
  filter(c_charge_degree != "O") %>%
  filter(score_text != 'N/A')
```

We want to convert the jail in and out to time to how long they spent in jail. We will convert those to datetime format and take the difference in days. 
```{r}
compas_scores$c_jail_out <- strptime(compas_scores$c_jail_out, format = '%Y-%m-%d %H:%M:%S')
compas_scores$c_jail_in <- strptime(compas_scores$c_jail_in, format = '%Y-%m-%d %H:%M:%S')
compas_scores$time_spent <- difftime(compas_scores$c_jail_out, compas_scores$c_jail_in, units='days')
compas_scores$time_spent <- as.numeric(compas_scores$time_spent)
```

We will only use a subset of features. We will use sex, age, race, juvenile felony count, juvenile misdemeanor count, juvenile other count, priors count, the charge degree, and how long they were in jail for (for the crime directly linked to the Compas score). The response will be whether or not they recidivated. The goal with out model is to predict whether or not individuals will recidivate based off of the selected features. 

```{r}
#View(compas_scores)
names(compas_scores)
df_recid <- compas_scores[, c(6, 8, 10, 11, 13, 14, 15, 23, 25, 54)]
```

Split up our train and test data. Roughly a 75-25 percent split.
```{r}
train <- sample(nrow(df_recid), 4500)
df.train <- df_recid[train, ]
df.test <- df_recid[-train, ]
```


Fit a logistic regression model.
```{r}
model <- glm(is_recid ~ ., data = df.train, family = binomial(link='logit'))
summary(model)
```

Look at the training performance for the model created above:
```{r}
preds <- predict(model, newdata = df.train, type = "response")
# use caret and compute a confusion matrix
confusionMatrix(data = as.numeric(preds>0.5), reference = df.train$is_recid)
```

Look at the testing performance:
```{r}
preds <- predict(model, newdata = df.test, type = "response")
# use caret and compute a confusion matrix
confusionMatrix(data = as.numeric(preds>0.5), reference = df.test$is_recid)
```

The training and testing performance are fairly comparable for the various metrics. The error for both could be significantly improved.